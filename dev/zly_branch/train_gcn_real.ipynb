{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyft: Training with multi-mode confidence\n",
    "\n",
    "![](http://www.l5kit.org/_images/av.jpg)\n",
    "<cite>The image from L5Kit official document: <a href=\"http://www.l5kit.org/README.html\">http://www.l5kit.org/README.html</a></cite>\n",
    "\n",
    "Continued from the previous kernel:\n",
    " - [Lyft: Comprehensive guide to start competition](https://www.kaggle.com/corochann/lyft-comprehensive-guide-to-start-competition)\n",
    " - [Lyft: Deep into the l5kit library](https://www.kaggle.com/corochann/lyft-deep-into-the-l5kit-library)\n",
    "\n",
    "In this kernel, I will run **pytorch CNN model training**. Especially, followings are new items to try:\n",
    " - Predict **multi-mode with confidence**: As written in [evaluation metric](https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/overview/evaluation) page, we can predict **3 modes** of motion trajectory.\n",
    " - Training loss with **competition evaluation metric**\n",
    " - Use Training abstraction library **`pytorch-ignite` and `pytorch-pfn-extras`**.\n",
    "\n",
    "\n",
    "[Update 2020/9/6]<br/>\n",
    "Published prediction kernel: [Lyft: Prediction with multi-mode confidence](https://www.kaggle.com/corochann/lyft-prediction-with-multi-mode-confidence)<br/>\n",
    "Try yourself how good score you can get using only single model without ensemble! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n",
    " - Please add [pestipeti/lyft-l5kit-unofficial-fix](https://www.kaggle.com/pestipeti/lyft-l5kit-unofficial-fix) as utility script.\n",
    "    - Official utility script \"[philculliton/kaggle-l5kit](https://www.kaggle.com/mathurinache/kaggle-l5kit)\" does not work with pytorch GPU.\n",
    " - Please add [lyft-config-files](https://www.kaggle.com/jpbremer/lyft-config-files) as dataset\n",
    " \n",
    "See previous kernel [Lyft: Comprehensive guide to start competition](https://www.kaggle.com/corochann/lyft-comprehensive-guide-to-start-competition) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:44.939659Z",
     "iopub.status.busy": "2022-10-13T03:41:44.939247Z",
     "iopub.status.idle": "2022-10-13T03:41:44.944832Z",
     "shell.execute_reply": "2022-10-13T03:41:44.944109Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/pfnet/pytorch-pfn-extras/releases/tag/v0.3.1\n",
    "# !pip install pytorch-pfn-extras==0.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:44.949052Z",
     "iopub.status.busy": "2022-10-13T03:41:44.948344Z",
     "iopub.status.idle": "2022-10-13T03:41:46.372877Z",
     "shell.execute_reply": "2022-10-13T03:41:46.372392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4012237/3467773202.py:16: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- setup ---\n",
    "# pd.set_option('max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:46.376031Z",
     "iopub.status.busy": "2022-10-13T03:41:46.375772Z",
     "iopub.status.idle": "2022-10-13T03:41:47.004815Z",
     "shell.execute_reply": "2022-10-13T03:41:47.004286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l5kit version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "import l5kit\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\n",
    "from l5kit.geometry import transform_points\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from l5kit.data import PERCEPTION_LABELS\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "rc('animation', html='jshtml')\n",
    "print(\"l5kit version:\", l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.007432Z",
     "iopub.status.busy": "2022-10-13T03:41:47.007084Z",
     "iopub.status.idle": "2022-10-13T03:41:47.052361Z",
     "shell.execute_reply": "2022-10-13T03:41:47.051835Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "import pytorch_pfn_extras.training.extensions as E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "\n",
    "To define loss function to calculate competition evaluation metric **in batch**.<br/>\n",
    "It works with **pytorch tensor, so it is differentiable** and can be used for training Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.055363Z",
     "iopub.status.busy": "2022-10-13T03:41:47.055168Z",
     "iopub.status.idle": "2022-10-13T03:41:47.063534Z",
     "shell.execute_reply": "2022-10-13T03:41:47.062990Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "    # print(f\"pred.shape : {pred.shape}\")\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"wrong shape for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "pytorch model definition. Here model outputs both **multi-mode trajectory prediction & confidence of each trajectory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.066130Z",
     "iopub.status.busy": "2022-10-13T03:41:47.065962Z",
     "iopub.status.idle": "2022-10-13T03:41:47.274373Z",
     "shell.execute_reply": "2022-10-13T03:41:47.273853Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Model utils ---\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torch import nn\n",
    "from typing import Dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.276881Z",
     "iopub.status.busy": "2022-10-13T03:41:47.276710Z",
     "iopub.status.idle": "2022-10-13T03:41:47.280611Z",
     "shell.execute_reply": "2022-10-13T03:41:47.280124Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Utils ---\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_yaml(filepath, content, width=120):\n",
    "    with open(filepath, 'w') as f:\n",
    "        yaml.dump(content, f, width=width)\n",
    "\n",
    "\n",
    "def load_yaml(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = yaml.safe_load(f)\n",
    "    return content\n",
    "\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\n",
    "\n",
    "    Refer: https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary/23689767#23689767\n",
    "    \"\"\"  # NOQA\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.283628Z",
     "iopub.status.busy": "2022-10-13T03:41:47.283404Z",
     "iopub.status.idle": "2022-10-13T03:41:47.289299Z",
     "shell.execute_reply": "2022-10-13T03:41:47.288773Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet50',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1,\n",
    "        'render_ego_history':True,\n",
    "        'step_time':0.1\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [224, 224],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5,\n",
    "\n",
    "        'set_origin_to_bottom': True,\n",
    "        'disable_traffic_light_faces':False\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 12,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'valid_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'max_num_steps': 10000,\n",
    "        'checkpoint_every_n_steps': 5000,\n",
    "\n",
    "        # 'eval_every_n_steps': -1\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.292019Z",
     "iopub.status.busy": "2022-10-13T03:41:47.291802Z",
     "iopub.status.idle": "2022-10-13T03:41:47.294975Z",
     "shell.execute_reply": "2022-10-13T03:41:47.294499Z"
    }
   },
   "outputs": [],
   "source": [
    "flags_dict = {\n",
    "    \"debug\": True,\n",
    "    # --- Data configs ---\n",
    "    \"l5kit_data_folder\": \"/home/zhuhe/kaggle/input/lyft-motion-prediction-autonomous-vehicles\",\n",
    "    # --- Model configs ---\n",
    "    \"pred_mode\": \"multi\",\n",
    "    # --- Training configs ---\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"out_dir\": \"results/multi_train\",\n",
    "    \"epoch\": 2,\n",
    "    \"snapshot_freq\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Main script\n",
    "\n",
    "Now finished defining all the util codes. Let's start writing main script to train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading data\n",
    "\n",
    "Here we will only use the first dataset from the sample set. (sample.zarr data is used for visualization, please use train.zarr / validate.zarr / test.zarr for actual model training/validation/prediction.)<br/>\n",
    "We're building a `LocalDataManager` object. This will resolve relative paths from the config using the `L5KIT_DATA_FOLDER` env variable we have just set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.297906Z",
     "iopub.status.busy": "2022-10-13T03:41:47.297694Z",
     "iopub.status.idle": "2022-10-13T03:41:47.305318Z",
     "shell.execute_reply": "2022-10-13T03:41:47.304785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags: {'debug': True, 'l5kit_data_folder': '/home/zhuhe/kaggle/input/lyft-motion-prediction-autonomous-vehicles', 'pred_mode': 'multi', 'device': 'cuda:0', 'out_dir': 'results/multi_train', 'epoch': 2, 'snapshot_freq': 50}\n"
     ]
    }
   ],
   "source": [
    "flags = DotDict(flags_dict)\n",
    "out_dir = Path(flags.out_dir)\n",
    "os.makedirs(str(out_dir), exist_ok=True)\n",
    "print(f\"flags: {flags_dict}\")\n",
    "save_yaml(out_dir / 'flags.yaml', flags_dict)\n",
    "save_yaml(out_dir / 'cfg.yaml', cfg)\n",
    "debug = flags.debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:47.307611Z",
     "iopub.status.busy": "2022-10-13T03:41:47.307371Z",
     "iopub.status.idle": "2022-10-13T03:41:59.723162Z",
     "shell.execute_reply": "2022-10-13T03:41:59.722533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset...\n",
      "train_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n",
      "test_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = flags.l5kit_data_folder\n",
    "dm = LocalDataManager(None)\n",
    "\n",
    "print(\"Load dataset...\")\n",
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "valid_cfg = cfg[\"valid_data_loader\"]\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "train_path = \"scenes/train.zarr\" if debug else train_cfg[\"key\"]\n",
    "test_path = \"scenes/test.zarr\"\n",
    "train_zarr = ChunkedDataset(dm.require(train_path)).open()\n",
    "test_zarr = ChunkedDataset(dm.require(test_path)).open()\n",
    "print(\"train_zarr\", type(train_zarr))\n",
    "print(\"test_zarr\", type(test_zarr))\n",
    "train_ego_dataset = EgoDataset(cfg, train_zarr, rasterizer)\n",
    "train_agent_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "test_ego_dataset = EgoDataset(cfg, test_zarr, rasterizer)\n",
    "test_agent_dataset = AgentDataset(cfg, test_zarr, rasterizer)\n",
    "\n",
    "# valid_path = \"scenes/sample.zarr\" if debug else valid_cfg[\"key\"]\n",
    "# valid_zarr = ChunkedDataset(dm.require(valid_path)).open()\n",
    "# print(\"valid_zarr\", type(train_zarr))\n",
    "# valid_agent_dataset = AgentDataset(cfg, valid_zarr, rasterizer)\n",
    "# valid_dataset = TransformDataset(valid_agent_dataset, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:59.726574Z",
     "iopub.status.busy": "2022-10-13T03:41:59.726360Z",
     "iopub.status.idle": "2022-10-13T03:41:59.737459Z",
     "shell.execute_reply": "2022-10-13T03:41:59.736934Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_distance(centroid1, centroid2):\n",
    "    return np.sqrt(np.square(centroid1[0]-centroid2[0]) + np.square(centroid1[1]-centroid2[1]))\n",
    "# def change_all_list_to_ndarray(dic_in):\n",
    "\n",
    "def transform_one_scene_dataset(scene_ego_dataset, scene_agent_dataset, debug: False):\n",
    "    def add_element_into(ele_dict, ele):\n",
    "        temp_x = []\n",
    "        temp_x.extend(ele[\"curr_speed\"].flatten())\n",
    "        temp_x.extend(ele[\"history_positions\"].flatten())\n",
    "        temp_x.extend(ele[\"history_yaws\"].flatten())\n",
    "        temp_x.extend(ele[\"history_availabilities\"].flatten())\n",
    "        ele_dict[\"x\"].append(temp_x)\n",
    "        if len(ele_dict[\"index\"])== 0:\n",
    "            cur_index = 0\n",
    "        else:\n",
    "            cur_index = ele_dict[\"index\"][-1] + 1\n",
    "        for i in range(0,cur_index):\n",
    "            ele_dict[\"edge_attr\"].append(get_distance(ele[\"centroid\"], ele_dict[\"centroid\"][i])) # 双向图\n",
    "            ele_dict[\"edge_index\"][0].append(i)\n",
    "            ele_dict[\"edge_index\"][1].append(cur_index)\n",
    "            ele_dict[\"edge_attr\"].append(get_distance(ele[\"centroid\"], ele_dict[\"centroid\"][i]))\n",
    "            ele_dict[\"edge_index\"][1].append(i)\n",
    "            ele_dict[\"edge_index\"][0].append(cur_index)\n",
    "        ele_dict[\"target_positions\"].append(ele[\"target_positions\"])\n",
    "        ele_dict[\"target_availabilities\"].append(ele[\"target_availabilities\"])\n",
    "        ele_dict[\"centroid\"].append(ele[\"centroid\"])  # 这个元素是为了建图方便\n",
    "        ele_dict[\"index\"].append(cur_index)  # 这个元素是为了建图方便\n",
    "\n",
    "    return_np = [] # 这个的长度应该是247或者248的样子，并且这个就是frame_index\n",
    "\n",
    "    for ele in scene_ego_dataset:\n",
    "        ele_dict = {}\n",
    "        for name in [\"x\",\"edge_index\",\"edge_attr\",\"centroid\",\"index\",\"target_positions\",\"target_availabilities\"]:\n",
    "            if name == \"edge_index\":\n",
    "                ele_dict[name] = [[],[]]\n",
    "            else:\n",
    "                ele_dict[name] = []\n",
    "        add_element_into(ele_dict,ele)\n",
    "        return_np.append(ele_dict)\n",
    "    if debug:\n",
    "        print(f\"len(return_np) : {len(return_np)}\")\n",
    "    for ele in scene_agent_dataset:\n",
    "        curr_frame_index = ele[\"frame_index\"]\n",
    "        if debug:\n",
    "            print(ele[\"frame_index\"])\n",
    "        cur_dict = return_np[curr_frame_index]\n",
    "        add_element_into(cur_dict, ele)\n",
    "\n",
    "    for ele in return_np:\n",
    "        for key_ in ele.keys():\n",
    "            ele[key_] = np.array(ele[key_])\n",
    "\n",
    "        ele[\"x\"] = torch.tensor(ele[\"x\"])\n",
    "        ele[\"edge_index\"] = torch.tensor(ele[\"edge_index\"],dtype=torch.long)\n",
    "        ele[\"edge_attr\"] = torch.tensor(ele[\"edge_attr\"])\n",
    "        ele[\"target_positions\"] = torch.tensor(ele[\"target_positions\"])\n",
    "        ele[\"target_availabilities\"] = torch.tensor(ele[\"target_availabilities\"])\n",
    "\n",
    "    return return_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare model & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:41:59.739938Z",
     "iopub.status.busy": "2022-10-13T03:41:59.739776Z",
     "iopub.status.idle": "2022-10-13T03:42:00.025419Z",
     "shell.execute_reply": "2022-10-13T03:42:00.024831Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False, whether_dropout= False):\n",
    "        # TODO: Implement this function that initializes self.convs,\n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "            input_dim = hidden_dim\n",
    "\n",
    "        self.convs.append(GCNConv(input_dim, output_dim))\n",
    "        self.whether_dropout = whether_dropout\n",
    "\n",
    "        self.softmax=torch.nn.LogSoftmax()\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "\n",
    "\n",
    "    # def forward(self, x, edge_index,edge_attr):\n",
    "    #     # x = x.to(device) # 在模型to_divice很慢？\n",
    "    #     edge_attr = edge_attr.to(device)\n",
    "    #     edge_index = edge_index.to(device)\n",
    "    #     out = None\n",
    "    #     for layer in range(len(self.convs)-1):  #layer：层数\n",
    "    #         x=self.convs[layer](x,edge_index,edge_attr).to(torch.float)   #叠GCNConv\n",
    "    #         # x= x.to(torch.float)# 这个是因为他这的输出搞成了float64,导致大家数据形式不兼容\n",
    "    #         x=F.relu(x)  #叠relu,这个不会导致数据被转化成float,\n",
    "    #         if self.whether_dropout is True:\n",
    "    #             x=F.dropout(x,self.dropout,self.training)  #叠dropout。这个self.dropout看下文是概率。\n",
    "    #     #最后一层\n",
    "    #     out=self.convs[-1](x,edge_index,edge_attr)  #GCNVonv\n",
    "    #     if not self.return_embeds:\n",
    "    #         out=self.softmax(out)\n",
    "    def forward(self, batch_data):\n",
    "        out = None\n",
    "        x = batch_data.x\n",
    "        for layer in range(len(self.convs)-1):  #layer：层数\n",
    "            x=self.convs[layer](x,batch_data.edge_index,batch_data.edge_attr).to(torch.float)   #叠GCNConv\n",
    "\n",
    "            # x= x.to(torch.float)# 这个是因为他这的输出搞成了float64,导致大家数据形式不兼容\n",
    "            x=F.relu(x)  #叠relu,这个不会导致数据被转化成float,\n",
    "            if self.whether_dropout is True:\n",
    "                x=F.dropout(x,self.dropout,self.training)  #叠dropout。这个self.dropout看下文是概率。\n",
    "        #最后一层\n",
    "\n",
    "        out=self.convs[-1](x,batch_data.edge_index,batch_data.edge_attr)  #GCNVonv\n",
    "        if not self.return_embeds:\n",
    "            out=self.softmax(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:00.028211Z",
     "iopub.status.busy": "2022-10-13T03:42:00.028014Z",
     "iopub.status.idle": "2022-10-13T03:42:00.031223Z",
     "shell.execute_reply": "2022-10-13T03:42:00.030740Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    # 'device' = 'cpu'\n",
    "    'num_layers': 2,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 1000,\n",
    "    'train_scene_start': 10, # 这个该有多少，还要好好想想，因为我们存储的数据并不多，主要是egodataset的load速度那边被限制住了\n",
    "    'train_scene_end': 100,\n",
    "    'test_scene_start': 10,\n",
    "    'test_scene_end': 30,\n",
    "    'batch_size_gcn':512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:00.034047Z",
     "iopub.status.busy": "2022-10-13T03:42:00.033799Z",
     "iopub.status.idle": "2022-10-13T03:42:00.037069Z",
     "shell.execute_reply": "2022-10-13T03:42:00.036530Z"
    }
   },
   "outputs": [],
   "source": [
    "#dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', 'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', 'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'curr_speed', 'scene_index', 'host_id', 'timestamp', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:00.039827Z",
     "iopub.status.busy": "2022-10-13T03:42:00.039611Z",
     "iopub.status.idle": "2022-10-13T03:42:23.609191Z",
     "shell.execute_reply": "2022-10-13T03:42:23.608697Z"
    }
   },
   "outputs": [],
   "source": [
    "scene_ego_dataset = train_ego_dataset.get_scene_dataset(60)\n",
    "scene_agent_dataset = train_agent_dataset.get_scene_dataset(60)\n",
    "frame_dic_array = transform_one_scene_dataset(scene_ego_dataset,scene_agent_dataset,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:23.611668Z",
     "iopub.status.busy": "2022-10-13T03:42:23.611497Z",
     "iopub.status.idle": "2022-10-13T03:42:24.846919Z",
     "shell.execute_reply": "2022-10-13T03:42:24.846404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(45, 256)\n",
      "    (1): GCNConv(256, 100)\n",
      "  )\n",
      "  (softmax): LogSoftmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm,trange\n",
    "\n",
    "input_dim = len(frame_dic_array[0][\"x\"][0])\n",
    "model_gcn = GCN(input_dim=input_dim, hidden_dim=args[\"hidden_dim\"], output_dim = cfg[\"model_params\"][\"future_num_frames\"] * 2,num_layers=args[\"num_layers\"],dropout=args[\"dropout\"],return_embeds = True, whether_dropout=False)\n",
    "\n",
    "model_gcn = model_gcn.to(device=args['device'])\n",
    "\n",
    "print(model_gcn.eval())\n",
    "epoch = flags.epoch\n",
    "\n",
    "optimizer = torch.optim.Adam(model_gcn.parameters(), lr=args[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:24.849426Z",
     "iopub.status.busy": "2022-10-13T03:42:24.849240Z",
     "iopub.status.idle": "2022-10-13T03:42:24.857912Z",
     "shell.execute_reply": "2022-10-13T03:42:24.857425Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_batch(model, device, data_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    # for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            out=model(batch)\n",
    "            train_output=out.view([-1,50,2]).to(device)\n",
    "            train_label = batch.y[:,:,0:2]\n",
    "            train_availabilities = torch.squeeze(batch.y[:,:,0:1],dim=-1)\n",
    "            loss=loss_fn(train_label,train_output,train_availabilities)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def train(model, value_dic, train_idx, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out=model(torch.tensor(value_dic[\"x\"]),edge_index = torch.tensor(value_dic[\"edge_index\"],dtype=torch.long), edge_attr = torch.tensor(value_dic[\"edge_attr\"]))\n",
    "    if len(out.shape) <= 2:\n",
    "        out = torch.unsqueeze(out,0)\n",
    "\n",
    "    train_output=out.view([-1,50,2]).to(args['device'])  # 这里暂时是全部训练\n",
    "    train_label= torch.tensor(value_dic[\"target_positions\"], dtype = torch.float).to(args['device'])\n",
    "    train_availabilities = torch.tensor(value_dic[\"target_availabilities\"],dtype= torch.int).to(args['device'])\n",
    "    loss=loss_fn(train_label,train_output,train_availabilities) # 只预测一条路\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_with_batch(model, device, data_loader, loss_fn):\n",
    "\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss_array = []\n",
    "\n",
    "    # for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            out=model(batch)\n",
    "            train_output=out.view([-1,50,2]).to(device)\n",
    "            train_label = batch.y[:,:,0:2]\n",
    "            train_availabilities = torch.squeeze(batch.y[:,:,0:1],dim=-1)\n",
    "            loss=loss_fn(train_label,train_output,train_availabilities)\n",
    "            y_true.append(train_label.detach().cpu())\n",
    "            y_pred.append(train_output.detach().cpu())\n",
    "            loss_array.append(loss.item())\n",
    "\n",
    "    loss_array = np.array(loss_array)\n",
    "\n",
    "\n",
    "\n",
    "    return y_true,y_pred,loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:24.860171Z",
     "iopub.status.busy": "2022-10-13T03:42:24.860013Z",
     "iopub.status.idle": "2022-10-13T03:42:24.863191Z",
     "shell.execute_reply": "2022-10-13T03:42:24.862832Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import  DataLoader\n",
    "def convert_framearray_to_dataloader(frame_dic_array):\n",
    "    pyg_data_list = []\n",
    "    for ele in frame_dic_array:\n",
    "        pyg_data_list.append(Data(x = ele[\"x\"],edge_index=ele[\"edge_index\"],edge_attr=ele[\"edge_attr\"],y=torch.cat([ele[\"target_positions\"],torch.unsqueeze(ele[\"target_availabilities\"],dim=-1)],dim = -1)))\n",
    "    return DataLoader(pyg_data_list,batch_size=args['batch_size_gcn'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_all_data_into_memory(ego_dataset,agent_dataset,start_index,end_index):\n",
    "    return_array = []\n",
    "    for index_ in range(start_index,end_index):\n",
    "\n",
    "        scene_ego_dataset = ego_dataset.get_scene_dataset(index_)\n",
    "        scene_agent_dataset = agent_dataset.get_scene_dataset(index_)\n",
    "        frame_dic_array = transform_one_scene_dataset(scene_ego_dataset,scene_agent_dataset,debug=False)\n",
    "        dataloader = convert_framearray_to_dataloader(frame_dic_array)\n",
    "        return_array.append(dataloader)\n",
    "    return  return_array\n",
    "\n",
    "def prepare_dataloader_array():\n",
    "    train_dataloader = load_all_data_into_memory(train_ego_dataset,train_agent_dataset,args['train_scene_start'],args['train_scene_end'])\n",
    "    test_dataloader = load_all_data_into_memory(test_ego_dataset,test_agent_dataset,args['test_scene_start'],args['test_scene_end'])\n",
    "    return train_dataloader,test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader = prepare_dataloader_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(len(train_dataloader))\n",
    "# print(sys.getsizeof(train_dataloader[0]) / 1024 / 1024, 'MB')\n",
    "# for i in trange(0,100):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T03:42:24.865235Z",
     "iopub.status.busy": "2022-10-13T03:42:24.865059Z",
     "iopub.status.idle": "2022-10-13T13:02:10.076070Z",
     "shell.execute_reply": "2022-10-13T13:02:10.075668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 1/1000 [00:00<16:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548280.9707016058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                  | 11/1000 [00:09<14:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545922.9784631791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 21/1000 [00:18<14:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546030.1563842488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                                | 31/1000 [00:26<14:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547438.620622835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                               | 41/1000 [00:35<13:51,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544881.1288254085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                              | 51/1000 [00:43<13:47,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545097.623326054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                              | 61/1000 [00:52<13:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546319.3325396365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▉                                                                             | 71/1000 [01:00<13:30,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553201.972944307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 81/1000 [01:09<13:24,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543550.3497777766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                           | 91/1000 [01:17<13:12,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544874.7492271303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                         | 101/1000 [01:26<13:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545260.7726233786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████                                                                         | 111/1000 [01:34<12:52,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545008.3291249692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                        | 121/1000 [01:43<12:46,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544385.2100485127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▋                                                                       | 131/1000 [01:51<12:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538108.6454526975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                      | 141/1000 [02:00<12:29,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533599.7159682801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                     | 151/1000 [02:08<12:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540079.7463995505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▏                                                                    | 161/1000 [02:17<12:09,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534648.4450247609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████                                                                    | 171/1000 [02:26<12:01,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548585.7488938079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▊                                                                   | 181/1000 [02:34<11:53,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538463.7603074963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▋                                                                  | 191/1000 [02:43<11:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540982.3886730599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 201/1000 [02:51<11:35,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530373.5351042554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▎                                                                | 211/1000 [03:00<11:29,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538343.9599568185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 221/1000 [03:08<11:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539600.4513163081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▉                                                               | 231/1000 [03:17<11:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530526.6264239294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▊                                                              | 241/1000 [03:25<11:01,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535941.949322305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▌                                                             | 251/1000 [03:34<10:51,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535285.2037405728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▍                                                            | 261/1000 [03:42<10:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536038.0500157091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▏                                                           | 271/1000 [03:51<10:35,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535648.7693238148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████                                                           | 281/1000 [03:59<10:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537192.2968268548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▊                                                          | 291/1000 [04:08<10:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527928.5959870033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▋                                                         | 301/1000 [04:17<10:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537669.3236989838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▌                                                        | 311/1000 [04:25<09:55,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531817.5622333109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▎                                                       | 321/1000 [04:34<09:51,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527001.938382243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▏                                                      | 331/1000 [04:42<09:41,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538603.0675925637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▉                                                      | 341/1000 [04:51<09:33,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528583.1478713067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████▊                                                     | 351/1000 [04:59<09:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524151.81720893615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▌                                                    | 361/1000 [05:08<09:17,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532404.4122984319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████▍                                                   | 371/1000 [05:16<09:08,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536001.2287253402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                  | 381/1000 [05:25<08:58,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544524.0361366614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████████                                                  | 391/1000 [05:33<08:49,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520808.88911117025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▉                                                 | 401/1000 [05:42<08:40,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531456.4435198333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████▋                                                | 411/1000 [05:50<08:33,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531887.0045450135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▌                                               | 421/1000 [05:59<08:24,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535335.4210249336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████▎                                              | 431/1000 [06:07<08:16,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533831.3623808231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████▏                                             | 441/1000 [06:16<08:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525050.658412887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████▉                                             | 451/1000 [06:25<07:58,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536146.0789183999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▊                                            | 461/1000 [06:33<07:50,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529712.0231725893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▌                                           | 471/1000 [06:42<07:42,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523864.26790970843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████▍                                          | 481/1000 [06:50<07:33,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537041.952666463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████████▎                                         | 491/1000 [06:59<07:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518672.6328710631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 501/1000 [07:07<07:15,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526312.3406193793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████▉                                        | 511/1000 [07:16<07:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516999.124472804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▋                                       | 521/1000 [07:24<06:58,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516775.9197282292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████▌                                      | 531/1000 [07:33<06:48,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530334.06829055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▎                                     | 541/1000 [07:41<06:39,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533820.3362668564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▏                                    | 551/1000 [07:50<06:31,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525346.1708467702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████                                    | 561/1000 [07:58<06:22,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520645.0961876859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████▊                                   | 571/1000 [08:07<06:14,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533048.166125375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▋                                  | 581/1000 [08:16<06:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521722.09383171715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████▍                                 | 591/1000 [08:24<05:55,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512942.49360655947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▎                                | 601/1000 [08:33<05:47,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509997.3063541126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████                                | 611/1000 [08:41<05:40,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519908.70956536976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▉                               | 621/1000 [08:50<05:32,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512266.24950790673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████▋                              | 631/1000 [08:58<05:21,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511592.566846904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████▌                             | 641/1000 [09:07<05:12,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529047.0325970228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▍                            | 651/1000 [09:15<05:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521226.35835119954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████▏                           | 661/1000 [09:24<04:55,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510494.2835479294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████                           | 671/1000 [09:32<04:46,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539443.6136651796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▊                          | 681/1000 [09:41<04:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532517.2368999822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▋                         | 691/1000 [09:49<04:29,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539878.6490686871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 701/1000 [09:58<04:20,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521127.557807792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████▎                       | 711/1000 [10:06<04:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511187.4529201285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████                       | 721/1000 [10:15<04:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509797.8562274645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████▉                      | 731/1000 [10:24<03:54,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519423.1101178218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████▊                     | 741/1000 [10:32<03:45,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523971.4359262854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 751/1000 [10:41<03:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508140.80970283336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████▍                   | 761/1000 [10:49<03:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512898.0280576631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████▏                  | 771/1000 [10:58<03:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507484.58509861183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████                  | 781/1000 [11:06<03:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514771.8118364319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████▊                 | 791/1000 [11:15<03:02,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529190.616136807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▋                | 801/1000 [11:23<02:53,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522533.99138113216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████▌               | 811/1000 [11:32<02:45,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527173.2580793153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████▎              | 821/1000 [11:40<02:36,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524697.408199628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████▏             | 831/1000 [11:49<02:27,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508277.2957678252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████▉             | 841/1000 [11:58<02:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519468.08673456655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▊            | 851/1000 [12:06<02:10,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507298.5797345989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 861/1000 [12:15<02:01,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521291.6980613349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████▍          | 871/1000 [12:23<01:52,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506804.0112999325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 881/1000 [12:32<01:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504842.56101549184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████         | 891/1000 [12:40<01:35,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519953.93674231105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▉        | 901/1000 [12:49<01:26,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509071.9347826326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████▋       | 911/1000 [12:57<01:17,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514497.85382076725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████▌      | 921/1000 [13:06<01:09,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511509.85425575014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████▎     | 931/1000 [13:14<01:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527146.6642641186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 941/1000 [13:23<00:51,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503871.14516805595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 951/1000 [13:32<00:42,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504303.17002621375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████▊   | 961/1000 [13:40<00:34,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524404.3110238935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▌  | 971/1000 [13:49<00:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520003.4881795972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▍ | 981/1000 [13:57<00:16,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522613.10961376724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████▎| 991/1000 [14:06<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517771.9122594688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:13<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_file = open( 'test_output.txt', 'w+',encoding = 'utf-8' )\n",
    "for epoch in trange(1, 1 + args[\"epochs\"]):\n",
    "    loss_whole_scene_list = []\n",
    "    loss_this_epoch = 0\n",
    "    # for train_scene_index in trange(0,args['train_scene_end']-args['train_scene_start']):\n",
    "    for train_scene_index in range(0,args['train_scene_end']-args['train_scene_start']):\n",
    "\n",
    "        dataloader = train_dataloader[train_scene_index]\n",
    "\n",
    "\n",
    "        loss_each_frame = train_with_batch(model_gcn,args[\"device\"],dataloader,optimizer,pytorch_neg_multi_log_likelihood_single)\n",
    "        loss_this_scene = np.mean(np.array(loss_each_frame))\n",
    "        loss_this_epoch = loss_this_epoch + loss_this_scene\n",
    "\n",
    "    # print(loss_this_epoch)\n",
    "    if epoch % 10 == 1:\n",
    "        loss_list = []\n",
    "        for test_scene_index in range(0,args['test_scene_end']-args['test_scene_start']):\n",
    "\n",
    "            dataloader = test_dataloader[test_scene_index]\n",
    "            y_true,y_pred,loss = test_with_batch(model_gcn,args[\"device\"],dataloader,pytorch_neg_multi_log_likelihood_single)\n",
    "            loss_list.append(loss)\n",
    "        loss_list = np.array(loss_list)\n",
    "        test_file.write(str(loss_list.mean()))\n",
    "        print(str(loss_list.mean()))\n",
    "        test_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "test_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-13T13:02:10.079596Z",
     "iopub.status.busy": "2022-10-13T13:02:10.079399Z",
     "iopub.status.idle": "2022-10-13T13:02:10.100590Z",
     "shell.execute_reply": "2022-10-13T13:02:10.100012Z"
    }
   },
   "outputs": [],
   "source": [
    "print(frame_dic_array[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtrain training history results really easily by just accessing `LogReport` class, which is useful for managing a lot of experiments during kaggle competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The history log and model's weight are saved by \"extensions\" (`LogReport` and `E.snapshot_object` respectively) easily, which is a benefit of using training abstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T13:02:10.102975Z",
     "iopub.status.busy": "2022-10-13T13:02:10.102799Z",
     "iopub.status.idle": "2022-10-13T13:02:10.254308Z",
     "shell.execute_reply": "2022-10-13T13:02:10.253380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see training results directory\n",
    "\n",
    "!ls results/multi_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Items to try\n",
    "\n",
    "This kernel shows demonstration run of the training (`debug=True`). You can try these things to see how the score changes at first\n",
    " - set debug=False to train with actual training dataset\n",
    " - change training hyperparameters (training epoch, change optimizer, scheduler learning rate etc...)\n",
    "   - Especially, just training much longer time may improve the score.\n",
    " \n",
    "To go further, these items may be nice to try:\n",
    " - Change the cnn model (now simple resnet18 is used as baseline modeling)\n",
    " - Training the model using full dataset: [lyft-full-training-set](https://www.kaggle.com/philculliton/lyft-full-training-set)\n",
    " - Write your own rasterizer to prepare input image as motivation explained in previous kernel.\n",
    " - Consider much better scheme to predict multi-trajectory\n",
    "    - The model just predicts multiple trajectory at the same time in this kernel, but it is possible to collapse \"trivial\" solution where all trajectory converges to same. How to avoid this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next to go\n",
    "\n",
    "[Update 2020/9/6]<br/>\n",
    "Published prediction kernel: [Lyft: Prediction with multi-mode confidence](https://www.kaggle.com/corochann/lyft-prediction-with-multi-mode-confidence)<br/>\n",
    "Try yourself how good score you can get using only single model without ensemble! :)\n",
    "\n",
    "To understand the competition in more detail, please refer my other kernels too.\n",
    " - [Lyft: Comprehensive guide to start competition](https://www.kaggle.com/corochann/lyft-comprehensive-guide-to-start-competition)\n",
    " - [Lyft: Deep into the l5kit library](https://www.kaggle.com/corochann/lyft-deep-into-the-l5kit-library)\n",
    " - [Save your time, submit without kernel inference](https://www.kaggle.com/corochann/save-your-time-submit-without-kernel-inference)\n",
    " - [Lyft: pytorch implementation of evaluation metric](https://www.kaggle.com/corochann/lyft-pytorch-implementation-of-evaluation-metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reference\n",
    "\n",
    " - Paper of this Lyft Level 5 prediction dataset: [One Thousand and One Hours: Self-driving Motion Prediction Dataset](https://arxiv.org/abs/2006.14480)\n",
    " - [jpbremer/lyft-scene-visualisations](https://www.kaggle.com/jpbremer/lyft-scene-visualisations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">If this kernel helps you, please upvote to keep me motivated :)<br>Thanks!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
