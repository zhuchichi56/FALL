{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "from functools import partial\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from l5kit.data import ChunkedDataset, get_frames_slice_from_scenes\n",
    "from l5kit.dataset.utils import convert_str_to_fixed_length_tensor\n",
    "from l5kit.kinematic import Perturbation\n",
    "from l5kit.rasterization import Rasterizer, RenderContext\n",
    "from l5kit.sampling.agent_sampling import generate_agent_sample\n",
    "from l5kit.sampling.agent_sampling_vectorized import generate_agent_sample_vectorized\n",
    "from l5kit.vectorization.vectorizer import Vectorizer\n",
    "\n",
    "\n",
    "class BaseEgoDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cfg: dict,\n",
    "            zarr_dataset: ChunkedDataset,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get a PyTorch dataset object that can be used to train DNN\n",
    "\n",
    "        Args:\n",
    "            cfg (dict): configuration file\n",
    "            zarr_dataset (ChunkedDataset): the raw zarr dataset\n",
    "        \"\"\"\n",
    "        self.cfg = cfg\n",
    "        self.dataset = zarr_dataset\n",
    "        self.cumulative_sizes = self.dataset.scenes[\"frame_index_interval\"][:, 1]\n",
    "\n",
    "        # build a partial so we don't have to access cfg each time\n",
    "        self.sample_function = self._get_sample_function()\n",
    "\n",
    "    def _get_sample_function(self) -> Callable[..., dict]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of available AV frames\n",
    "\n",
    "        Returns:\n",
    "            int: the number of elements in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.dataset.frames)\n",
    "\n",
    "    def get_frame(self, scene_index: int, state_index: int, track_id: Optional[int] = None) -> dict:\n",
    "        \"\"\"\n",
    "        A utility function to get the rasterisation and trajectory target for a given agent in a given frame\n",
    "\n",
    "        Args:\n",
    "            scene_index (int): the index of the scene in the zarr\n",
    "            state_index (int): a relative frame index in the scene\n",
    "            track_id (Optional[int]): the agent to rasterize or None for the AV\n",
    "        Returns:\n",
    "            dict: the rasterised image in (Cx0x1) if the rast is not None, the target trajectory\n",
    "            (position and yaw) along with their availability, the 2D matrix to center that agent,\n",
    "            the agent track (-1 if ego) and the timestamp\n",
    "\n",
    "        \"\"\"\n",
    "        frames = self.dataset.frames[get_frames_slice_from_scenes(self.dataset.scenes[scene_index])]\n",
    "\n",
    "        tl_faces = self.dataset.tl_faces\n",
    "        # TODO (@lberg): this should be done in the sample function\n",
    "        if self.cfg[\"raster_params\"][\"disable_traffic_light_faces\"]:\n",
    "            tl_faces = np.empty(0, dtype=self.dataset.tl_faces.dtype)  # completely disable traffic light faces\n",
    "\n",
    "        data = self.sample_function(state_index, frames, self.dataset.agents, tl_faces, track_id)\n",
    "\n",
    "        # add information only, so that all data keys are always preserved\n",
    "        data[\"scene_index\"] = scene_index\n",
    "        data[\"host_id\"] = np.uint8(convert_str_to_fixed_length_tensor(self.dataset.scenes[scene_index][\"host\"]).cpu())\n",
    "        data[\"timestamp\"] = frames[state_index][\"timestamp\"]\n",
    "        data[\"track_id\"] = np.int64(-1 if track_id is None else track_id)  # always a number to avoid crashing torch\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        \"\"\"\n",
    "        Function called by Torch to get an element\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element to retrieve\n",
    "\n",
    "        Returns: please look get_frame signature and docstring\n",
    "\n",
    "        \"\"\"\n",
    "        if index < 0:\n",
    "            if -index > len(self):\n",
    "                raise ValueError(\"absolute value of index should not exceed dataset length\")\n",
    "            index = len(self) + index\n",
    "\n",
    "        scene_index = bisect.bisect_right(self.cumulative_sizes, index)\n",
    "\n",
    "        if scene_index == 0:\n",
    "            state_index = index\n",
    "        else:\n",
    "            state_index = index - self.cumulative_sizes[scene_index - 1]\n",
    "        return self.get_frame(scene_index, state_index)\n",
    "\n",
    "    def get_scene_dataset(self, scene_index: int) -> \"BaseEgoDataset\":\n",
    "        \"\"\"\n",
    "        Returns another EgoDataset dataset where the underlying data can be modified.\n",
    "        This is possible because, even if it supports the same interface, this dataset is np.ndarray based.\n",
    "\n",
    "        Args:\n",
    "            scene_index (int): the scene index of the new dataset\n",
    "\n",
    "        Returns:\n",
    "            EgoDataset: A valid EgoDataset dataset with a copy of the data\n",
    "\n",
    "        \"\"\"\n",
    "        dataset = self.dataset.get_scene_dataset(scene_index)\n",
    "        return BaseEgoDataset(self.cfg, dataset)\n",
    "\n",
    "    def get_scene_indices(self, scene_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given scene. EgoDataset iterates over frames, so this is just a matter\n",
    "        of finding the scene boundaries.\n",
    "        Args:\n",
    "            scene_idx (int): index of the scene\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        scenes = self.dataset.scenes\n",
    "        assert scene_idx < len(scenes), f\"scene_idx {scene_idx} is over len {len(scenes)}\"\n",
    "        return np.arange(*scenes[scene_idx][\"frame_index_interval\"])\n",
    "\n",
    "    def get_frame_indices(self, frame_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given frame. EgoDataset iterates over frames, so this will be a single element\n",
    "        Args:\n",
    "            frame_idx (int): index of the scene\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        frames = self.dataset.frames\n",
    "        assert frame_idx < len(frames), f\"frame_idx {frame_idx} is over len {len(frames)}\"\n",
    "        return np.asarray((frame_idx,), dtype=np.int64)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.dataset.__str__()\n",
    "\n",
    "\n",
    "class EgoDataset(BaseEgoDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cfg: dict,\n",
    "            zarr_dataset: ChunkedDataset,\n",
    "            rasterizer: Rasterizer,\n",
    "            perturbation: Optional[Perturbation] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get a PyTorch dataset object that can be used to train DNN\n",
    "\n",
    "        Args:\n",
    "            cfg (dict): configuration file\n",
    "            zarr_dataset (ChunkedDataset): the raw zarr dataset\n",
    "            rasterizer (Rasterizer): an object that support rasterisation around an agent (AV or not)\n",
    "            perturbation (Optional[Perturbation]): an object that takes care of applying trajectory perturbations.\n",
    "            None if not desired\n",
    "        \"\"\"\n",
    "        self.perturbation = perturbation\n",
    "        self.rasterizer = rasterizer\n",
    "        super().__init__(cfg, zarr_dataset)\n",
    "\n",
    "    def _get_sample_function(self) -> Callable[..., dict]:\n",
    "        render_context = RenderContext(\n",
    "            raster_size_px=np.array(self.cfg[\"raster_params\"][\"raster_size\"]),\n",
    "            pixel_size_m=np.array(self.cfg[\"raster_params\"][\"pixel_size\"]),\n",
    "            center_in_raster_ratio=np.array(self.cfg[\"raster_params\"][\"ego_center\"]),\n",
    "            set_origin_to_bottom=self.cfg[\"raster_params\"][\"set_origin_to_bottom\"],\n",
    "        )\n",
    "\n",
    "        return partial(\n",
    "            generate_agent_sample,\n",
    "            render_context=render_context,\n",
    "            history_num_frames=self.cfg[\"model_params\"][\"history_num_frames\"],\n",
    "            future_num_frames=self.cfg[\"model_params\"][\"future_num_frames\"],\n",
    "            step_time=self.cfg[\"model_params\"][\"step_time\"],\n",
    "            filter_agents_threshold=self.cfg[\"raster_params\"][\"filter_agents_threshold\"],\n",
    "            rasterizer=self.rasterizer,\n",
    "            perturbation=self.perturbation,\n",
    "        )\n",
    "\n",
    "    def get_frame(self, scene_index: int, state_index: int, track_id: Optional[int] = None) -> dict:\n",
    "        data = super().get_frame(scene_index, state_index, track_id=track_id)\n",
    "        # TODO (@lberg): this should not be here but in the rasterizer\n",
    "        data[\"image\"] = data[\"image\"].transpose(2, 0, 1)  # 0,1,C -> C,0,1\n",
    "        return data\n",
    "\n",
    "    def get_scene_dataset(self, scene_index: int) -> \"EgoDataset\":\n",
    "        \"\"\"\n",
    "        Returns another EgoDataset dataset where the underlying data can be modified.\n",
    "        This is possible because, even if it supports the same interface, this dataset is np.ndarray based.\n",
    "\n",
    "        Args:\n",
    "            scene_index (int): the scene index of the new dataset\n",
    "\n",
    "        Returns:\n",
    "            EgoDataset: A valid EgoDataset dataset with a copy of the data\n",
    "\n",
    "        \"\"\"\n",
    "        dataset = self.dataset.get_scene_dataset(scene_index)\n",
    "        return EgoDataset(self.cfg, dataset, self.rasterizer, self.perturbation)\n",
    "\n",
    "\n",
    "class EgoDatasetVectorized(BaseEgoDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cfg: dict,\n",
    "            zarr_dataset: ChunkedDataset,\n",
    "            vectorizer: Vectorizer,\n",
    "            perturbation: Optional[Perturbation] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get a PyTorch dataset object that can be used to train DNNs with vectorized input\n",
    "\n",
    "        Args:\n",
    "            cfg (dict): configuration file\n",
    "            zarr_dataset (ChunkedDataset): the raw zarr dataset\n",
    "            vectorizer (Vectorizer): a object that supports vectorization around an AV\n",
    "            perturbation (Optional[Perturbation]): an object that takes care of applying trajectory perturbations.\n",
    "        None if not desired\n",
    "        \"\"\"\n",
    "        self.perturbation = perturbation\n",
    "        self.vectorizer = vectorizer\n",
    "        super().__init__(cfg, zarr_dataset)\n",
    "\n",
    "    def _get_sample_function(self) -> Callable[..., dict]:\n",
    "        return partial(\n",
    "            generate_agent_sample_vectorized,\n",
    "            history_num_frames_ego=self.cfg[\"model_params\"][\"history_num_frames_ego\"],\n",
    "            history_num_frames_agents=self.cfg[\"model_params\"][\"history_num_frames_agents\"],\n",
    "            future_num_frames=self.cfg[\"model_params\"][\"future_num_frames\"],\n",
    "            step_time=self.cfg[\"model_params\"][\"step_time\"],\n",
    "            filter_agents_threshold=self.cfg[\"raster_params\"][\"filter_agents_threshold\"],\n",
    "            perturbation=self.perturbation,\n",
    "            vectorizer=self.vectorizer\n",
    "        )\n",
    "\n",
    "    def get_scene_dataset(self, scene_index: int) -> \"EgoDatasetVectorized\":\n",
    "        dataset = self.dataset.get_scene_dataset(scene_index)\n",
    "        return EgoDatasetVectorized(self.cfg, dataset, self.vectorizer, self.perturbation)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
